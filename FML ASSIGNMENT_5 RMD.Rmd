---
title: "Assignment_5"
author: "Nikhila Reddy"
date: "2024-04-06"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Displaying the required libraries
library(cluster)
library(caret)
```

```{r}
library(dendextend)
```

```{r}
library(knitr)
library(factoextra)
```
```{r}
library(readr)
```

#Creating a dataset consisting solely of numerical values through the importation of data.
```{r}
library(readr)
SB_Cereals <- read.csv("C:\\Users\\Nikhi\\Downloads\\Cereals.csv")
Num_data <- data.frame(SB_Cereals[,4:16])
```

#Data with missing values should be eliminated.
```{r}
Num_data <- na.omit(Num_data)
```

#Normalizing the data
```{r}
SB_Cereals_normalise <- scale(Num_data)
```

#Utilize the scaled data for hierarchical clustering employing the Euclidean Distance technique.
```{r}
Dist <- dist(SB_Cereals_normalise, method = "euclidean")
H_clust <- hclust(Dist, method = "complete")
```

#The process of plotting the dendrogram.
```{r}
plot(H_clust, cex = 0.7, hang = -1)
```


#Performing clustering using single linkage, complete linkage, and the Agnes function, as well as average linkage and Ward methods.

```{r}
single_Hclust <- agnes(SB_Cereals_normalise, method = "single")
complete_Hclust <- agnes(SB_Cereals_normalise, method = "complete")
average_Hclust <- agnes(SB_Cereals_normalise, method = "average")
ward_Hclust <- agnes(SB_Cereals_normalise, method = "ward")
```

#Selecting the most effective approach
```{r}
print(single_Hclust$ac)
```
```{r}
print(complete_Hclust$ac)
```
```{r}
print(average_Hclust$ac)
```
```{r}
print(ward_Hclust$ac)
```
#The Ward method emerges as the most effective strategy, supported by its high value of 0.9046042, substantiated by the provided data.

2- Choosing the clusters:

```{r}
pltree(ward_Hclust, cex = 0.5, hang = -1, main = "Dendrogram of agnes(Using Ward)")
rect.hclust(ward_Hclust, k =5, border = 2.7)
```
```{r}
S_Group <- cutree(ward_Hclust, k = 5)
D_frame_2 <- as.data.frame(cbind(SB_Cereals_normalise, S_Group))
```

```{r}
fviz_cluster(list(data= D_frame_2, cluster = S_Group))
```

From the above observation, clusters can be selected.

#determining the stability and structure of the clusters.
```{r}
#Building Partitions
set.seed(123)
One_partition <- Num_data[1:50,]
Two_partition <- Num_data[51:74,]
```

##Conducting Hierarchical Clustering with a specified value of k = 5.
```{r}
single_sb <- agnes(scale(One_partition), method = "single")
complete_sb <- agnes(scale(One_partition), method = "complete")
average_sb <- agnes(scale(One_partition), method = "average")
ward_sb <- agnes(scale(One_partition), method = "ward")
cbind(single=single_sb$ac , complete_sb$ac, average = average_sb$ac, ward = ward_sb$ac)
```
```{r}
pltree(ward_sb, cex = 0.6, hang = -1, main = "Dendogram of Agnes with Partitioned Data (Using Ward)")
rect.hclust(ward_sb, k = 5, border = 2:7)
```
```{r}
cut_2 <- cutree(ward_sb, k = 5)
```

```{r}
#the centroids are calculated.
Sb_result <- as.data.frame(cbind(One_partition, cut_2))
Sb_result[Sb_result$cut_2==1,]
```
```{r}
one_centroid <- colMeans(Sb_result[Sb_result$cut_2==1,])
Sb_result[Sb_result$cut_2==2,]
```
```{r}
two_centriod <- colMeans(Sb_result[Sb_result$cut_2==2,])
Sb_result[Sb_result$cut_2==3,]
```
```{r}
three_centroid <- colMeans(Sb_result[Sb_result$cut_2==3,])
Sb_result[Sb_result$cut_2==4,]
```
```{r}
four_centroid <- colMeans(Sb_result[Sb_result$cut_2==4,])
centroids <- rbind(one_centroid, two_centriod, three_centroid, four_centroid)
x2 <- as.data.frame(rbind(centroids[,-14], Two_partition))
```

#figuring out the Dist.
```{r}
Dist_1 <- get_dist(x2)
Matrix_1 <- as.matrix(Dist_1)
dataframe1 <- data.frame(data=seq(1,nrow(Two_partition),1), Clusters = rep (0,nrow(Two_partition)))
for(i in 1:nrow(Two_partition))
  {dataframe1[i,2] <- which.min(Matrix_1[i+4, 1:4])}
dataframe1
```
```{r}
cbind(D_frame_2$S_Group[51:74], dataframe1$Clusters)
```
```{r}
table(D_frame_2$S_Group[51:74]== dataframe1$Clusters)
```
#Out of the 24 observations made above, 12 are inaccurate, while 12 are accurate. Therefore, we can conclude that the model exhibits partial instability.

3- The elementary public schools would like to choose a set of cereals to include in their
daily cafeterias. Every day a different cereal is offered, but all cereals should support a
healthy diet. For this goal, you are requested to find a cluster of “healthy cereals.”
Should the data be normalized? If not, how should they be used in the cluster analysis?

```{r}
#Clustering Healthy SB_Cereals.
Healthy_SB_Cereals <- SB_Cereals
Healthy_SB_Cereals_RD <- na.omit(Healthy_SB_Cereals)
clust <- cbind(Healthy_SB_Cereals_RD, S_Group)
clust[clust$S_Group==1,]
```
```{r}
clust[clust$S_Group==2,]
```
```{r}
clust[clust$S_Group==3,]
```
```{r}
clust[clust$S_Group==4,]
```
```{r}
#Mean ratings are used to select the best cluster.
mean(clust[clust$S_Group==1, "rating"])
```
```{r}
mean(clust[clust$S_Group==2,"rating"])
```
```{r}
mean(clust[clust$S_Group==3, "rating"])
```
```{r}
mean(clust[clust$S_Group==4,"rating"])
```
#Based on the provided data, Cluster 1 could be selected since it has the highest value.

#Hence, Group 1 could be identified as the cluster representing a healthy diet..

